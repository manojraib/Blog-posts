{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "title: Basic web scraping in Python  \n",
    "date: 2015-12-23  \n",
    "comments: false  \n",
    "tags: Python, web scraping\n",
    "keywords: python, programming, pandas, matplotlib, web scraping, movielens, christmas, sql  \n",
    "\n",
    "---\n",
    "\n",
    "If you followed along with my analysis of the top Christmas movies according to the MovieLens 10M dataset, you would remember I obtained the list of Christmas movies by [web scraping](https://en.wikipedia.org/wiki/Web_scraping) this [page](http://www.timeout.com/london/film/the-50-best-christmas-movies). I am fairly new to web scraping, so this is one of my first serious attempts to get data in this manner. However, you can see that even with a basic understanding of how to find information in webpages it is relatively easy to extract the information you need. Hopefully this will help anyone also new to web scraping to get started."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up your virtualenv\n",
    "\n",
    "The first step as always with Python analyses is to set up a virtualenv. If you're unfamiliar with how to do this, [this blog post]({filename}2015-11-18-reddit-api-part-1.md) explains how (and I promise you will never want to go back to system-installing packages!). Once you're in your virtualenv, install the following packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!pip install lxml\n",
    "!pip install cssselect\n",
    "!pip install requests\n",
    "!pip install jupyter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then enter `!ipython notebook` into the command line and start a new notebook (alternatively you can use your preferred Python [IDE](https://en.wikipedia.org/wiki/Integrated_development_environment)). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping the movie titles\n",
    "\n",
    "Once we're ready to go, we first import our newly installed packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import lxml.html\n",
    "from lxml.cssselect import CSSSelector\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next thing we need to do is find out where our titles are in the page. This is pretty straightforward in a browser that supports developer tools, like [Chrome](https://www.google.com/chrome/). With Chrome, we simply need to go to our list of top 50 movies, right click, and select \"Inspect\". This brings up the developer tools for the page.\n",
    "\n",
    "<img src=\"/figure/web_scraping_inspect_element.png\" title=\"Inspect element button\" alt=\"Finding elements on page in Chrome.\" style=\"display: block; margin: auto;\" />\n",
    "\n",
    "Once you've done that, the developer tools open on the right of the screen. In the image above, I have highlighted a button that allows you to view the tags associated with any element of the page. If you click on this and select one of the movie titles, it will take you to the title tag, like so:\n",
    "\n",
    "<img src=\"/figure/web_scraping_title_element.png\" title=\"Inspect title\" alt=\"Finding 'The Santa Clause' title in the page.\" style=\"display: block; margin: auto;\" />\n",
    "\n",
    "Ah ha! We can see that the first title, 'The Santa Clause', is tagged as `div.feature-item__text h3 a`. However, looking through the rest of the movies (for example, 'Joyeux NoÃ«l') are tagged only as `div.feature-item__text h3`. Huh, that creates some problems. To get around this, the function below checks whether the title tag contains an `a` (anchor) element, and if so, looks in here for the title. Otherwise, it looks in the `h3` tag for the title."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_title(node):\n",
    "    '''\n",
    "    Extracts the movie title from the URL http://www.timeout.com/london/film/the-50-best-christmas-movies\n",
    "    taking into account that some titles are tagged as h3, and some as h3 a.\n",
    "    '''\n",
    "    h3_elem = node.cssselect('div.feature-item__text h3')[0]\n",
    "    anchor_elem = h3_elem.cssselect('a')\n",
    "    if len(anchor_elem) == 0:\n",
    "        return h3_elem.text_content()\n",
    "    else:\n",
    "        return anchor_elem[0].text_content()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've set up where to look for the titles, we can extract the data from the website. The `requests.get()` function pulls the data from the website, and the `lxml.html.fromstring(r.text)` command parses the html into the `tree` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get data and transform to text\n",
    "r = requests.get(\"http://www.timeout.com/london/film/the-50-best-christmas-movies\")\n",
    "tree = lxml.html.fromstring(r.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now select the parts of the html we want. We can see in the screenshot above that the titles are contained within the `article.feature-item` tag, therefore we select all data under this tag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "items_selector = CSSSelector('article.feature-item')\n",
    "all_items = items_selector(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now apply our `get_title` function to the items we pulled out using list comprehension. Let's have a look at what we got:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The Santa Clause (1994)',\n",
       " 'Reindeer Games (2000)',\n",
       " 'The Family Stone (2005)',\n",
       " 'Love Actually (2003)',\n",
       " 'Merry Christmas Mr Lawrence (1983)',\n",
       " u'\\n                                            Joyeux No\\xebl (2005)\\n                                        ',\n",
       " '\\n                                            Christmas in Connecticut (1945)\\n                                        ',\n",
       " 'The Polar Express (2004)',\n",
       " 'A Christmas Story (1983)',\n",
       " 'The Holiday (2006)',\n",
       " 'Planes, Trains and Automobiles (1987)',\n",
       " 'Lethal Weapon (1987)',\n",
       " 'Ghostbusters II (1989)',\n",
       " '\\n                                            Prancer (1989)\\n                                        ',\n",
       " 'Holiday Inn (1942)',\n",
       " 'White Christmas (1954)',\n",
       " u'\\n                                            Mickey\\u2019s Christmas Carol (1983)\\n                                        ',\n",
       " u'National Lampoon\\u2019s Christmas Vacation (1989)',\n",
       " '\\n                                            Babes In Toyland (1934)\\n                                        ',\n",
       " u'\\n                                            \\u2019R-Xmas (2001)\\n                                        ',\n",
       " 'Meet Me In St Louis (1944)',\n",
       " 'About a Boy (2002)',\n",
       " 'Christmas Evil (1980)',\n",
       " 'Die Hard (1988)',\n",
       " 'Die Hard 2 (1990)',\n",
       " '\\n                                            A Christmas Carol (1938)\\n                                        ',\n",
       " 'While You Were Sleeping (1995)',\n",
       " 'Arthur Christmas (2011)',\n",
       " 'Trading Places (1983)',\n",
       " 'Brazil (1985)',\n",
       " u'Bridget Jones\\u2019 Diary (2001) ',\n",
       " 'The Nightmare Before Christmas (1993)',\n",
       " 'The Muppet Christmas Carol (1992)',\n",
       " 'How The Grinch Stole Christmas (2000)',\n",
       " 'The Long Kiss Goodnight (1996)',\n",
       " 'In Bruges (2008)',\n",
       " 'Miracle on 34th Street (1947)',\n",
       " 'The Chronicles Of Narnia: The Lion, The Witch and the Wardrobe (2005)',\n",
       " '8 Women (2001)',\n",
       " 'Scrooged (1988)',\n",
       " 'Batman Returns (1992)',\n",
       " 'A Charlie Brown Christmas (1965)',\n",
       " 'Kiss Kiss Bang Bang (2005)',\n",
       " 'The Snowman (1982)',\n",
       " 'Edward Scissorhands (1990)',\n",
       " 'Home Alone (1990)',\n",
       " 'Gremlins (1984)',\n",
       " 'Bad Santa (2003)',\n",
       " 'Elf (2003)',\n",
       " u'It\\u2019s a Wonderful Life (1946)']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h3_titles = [get_title(item) for item in all_items[0:50]]\n",
    "h3_titles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, this is a bit of a mess. To use it we need to clean it up using a bit of string manipulation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning up the list of titles\n",
    "\n",
    "The first major issue you can see is that a number of titles contain whitespace and newline escape characters (`\\n`). We'll get rid of the newline by calling the `replace` method and the whitespace using the `strip` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Strip newline and whitespace from titles\n",
    "titles = [t.replace('\\n', '').strip() for t in h3_titles]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we don't need to preserve the unicode formatting, we'll use a lazy method to get our apostrophes back. We first call the `encode('utf8')` method, which converts the text into UTF-8 characters. We then call the `replace` method again to convert this format into plain text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert from unicode and replace apostraphes\n",
    "titles = [t.encode('utf8').replace('\\xe2\\x80\\x99', '\\'') for t in titles]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you followed my previous post on the Christmas analyses, you would have seen that titles that start with \"The\" or \"A\" have this leading article moved to the end of the title. For example, \"The Santa Clause (1994) is represented as \"Santa Clause, The (1994)\" in the MovieLens 10M dataset. To change all of these, I wrote two small loops, which first use a regex to check if the title starts with \"The\" or \"A\", removes this word from the beginning of the sentence, and uses indexing to place it at the end of the title. The loop relies on the `enumerate` function to get both the index and content of each item in the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Replace titles in the form \"The [title]\" to \"[title], The\"\n",
    "import re\n",
    "for i, t in enumerate(titles):\n",
    "    if re.match(\"^The\", t):\n",
    "        t = re.sub(r'^The ', '', t)\n",
    "        titles[i] = t[:-7] + \", The\" + t[-7:]\n",
    " \n",
    "# Replace titles in the form \"A [title]\" to \"[title], A\"       \n",
    "for i, t in enumerate(titles):\n",
    "    if re.match(\"^A\", t):\n",
    "        t = re.sub(r'^A ', '', t)\n",
    "        titles[i] = t[:-7] + \", A\" + t[-7:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, I haven't yet replace the UTF-8 character for 'Ã¶' in 'Joyeux NoÃ«l'. However, as I know there are issue with this character in the MovieLens 10M dataset as well, I'll just truncate it to 'Joyeux' which is sufficient to get an exact match with this movie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Change \"Joyeux NoÃ«l\" to just \"Joyeux\" due to special character matching issues        \n",
    "titles[5] = titles[5].replace('Joyeux No\\xc3\\xabl (2005)', \n",
    "                              'Joyeux')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a complete list! Let's have a look at how it's turned out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Santa Clause, The (1994)',\n",
       " 'Reindeer Games (2000)',\n",
       " 'Family Stone, The (2005)',\n",
       " 'Love Actually (2003)',\n",
       " 'Merry Christmas Mr Lawrence (1983)',\n",
       " 'Joyeux No\\xc3\\xabl (2005)',\n",
       " 'Christmas in Connecticut (1945)',\n",
       " 'Polar Express, The (2004)',\n",
       " 'Christmas Story, A (1983)',\n",
       " 'Holiday, The (2006)',\n",
       " 'Planes, Trains and Automobiles (1987)',\n",
       " 'Lethal Weapon (1987)',\n",
       " 'Ghostbusters II (1989)',\n",
       " 'Prancer (1989)',\n",
       " 'Holiday Inn (1942)',\n",
       " 'White Christmas (1954)',\n",
       " \"Mickey's Christmas Carol (1983)\",\n",
       " \"National Lampoon's Christmas Vacation (1989)\",\n",
       " 'Babes In Toyland (1934)',\n",
       " \"'R-Xmas (2001)\",\n",
       " 'Meet Me In St Louis (1944)',\n",
       " 'About a Boy, A (2002)',\n",
       " 'Christmas Evil (1980)',\n",
       " 'Die Hard (1988)',\n",
       " 'Die Hard 2 (1990)',\n",
       " 'Christmas Carol, A (1938)',\n",
       " 'While You Were Sleeping (1995)',\n",
       " 'Arthur Christmas, A (2011)',\n",
       " 'Trading Places (1983)',\n",
       " 'Brazil (1985)',\n",
       " \"Bridget Jones' Diary (2001)\",\n",
       " 'Nightmare Before Christmas, The (1993)',\n",
       " 'Muppet Christmas Carol, The (1992)',\n",
       " 'How The Grinch Stole Christmas (2000)',\n",
       " 'Long Kiss Goodnight, The (1996)',\n",
       " 'In Bruges (2008)',\n",
       " 'Miracle on 34th Street (1947)',\n",
       " 'Chronicles Of Narnia: The Lion, The Witch and the Wardrobe, The (2005)',\n",
       " '8 Women (2001)',\n",
       " 'Scrooged (1988)',\n",
       " 'Batman Returns (1992)',\n",
       " 'Charlie Brown Christmas, A (1965)',\n",
       " 'Kiss Kiss Bang Bang (2005)',\n",
       " 'Snowman, The (1982)',\n",
       " 'Edward Scissorhands (1990)',\n",
       " 'Home Alone (1990)',\n",
       " 'Gremlins (1984)',\n",
       " 'Bad Santa (2003)',\n",
       " 'Elf (2003)',\n",
       " \"It's a Wonderful Life (1946)\"]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last thing left to do is to export the whole thing to a text file. In the case of my analysis, I then imported this into an SQL database with the MovieLens 10M dataset, and I will describe how I used it in my next blog post."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Export to text file                              \n",
    "f = open(\"christmas_movies.txt\", \"w\")\n",
    "f.write(\"\\n\".join(map(lambda x: str(x), titles)))\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
